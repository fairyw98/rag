{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539c34c2-e46b-4cd5-8160-ea57e2ca8e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正克隆到 'all-MiniLM-L6-v2'...\n",
      "remote: Enumerating objects: 112, done.\u001b[K\n",
      "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
      "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
      "remote: Total 112 (delta 44), reused 53 (delta 19), pack-reused 0 (from 0)\u001b[K\n",
      "接收对象中: 100% (112/112), 359.04 KiB | 2.90 MiB/s, 完成.\n",
      "处理 delta 中: 100% (44/44), 完成.\n",
      "过滤内容: 100% (15/15), 930.41 MiB | 13.19 MiB/s, 完成.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://hf-mirror.com/sentence-transformers/all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b70793-f9b6-437a-8d7b-c8ad12569a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正克隆到 'text2vec-base-chinese'...\n",
      "remote: Enumerating objects: 23, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 23 (delta 0), reused 0 (delta 0), pack-reused 20 (from 1)\u001b[K\n",
      "展开对象中: 100% (23/23), 161.11 KiB | 2.40 MiB/s, 完成.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://hf-mirror.com/GanymedeNil/text2vec-base-chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37117b3f-475b-49e6-88c9-f4903c5ac0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正克隆到 'paraphrase-multilingual-MiniLM-L12-v2'...\n",
      "remote: Enumerating objects: 100, done.\u001b[K\n",
      "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
      "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
      "remote: Total 100 (delta 25), reused 0 (delta 0), pack-reused 41 (from 1)\u001b[K\n",
      "接收对象中: 100% (100/100), 3.45 MiB | 8.77 MiB/s, 完成.\n",
      "处理 delta 中: 100% (38/38), 完成.\n",
      "过滤内容: 100% (17/17), 4.30 GiB | 9.61 MiB/s, 完成.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://hf-mirror.com/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84440e11-b356-4092-b0bc-d9b9842c5606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7db4ef69-4020-4580-8ab7-cee8e4e6511c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Collecting langchain\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/d4/49/6e933837da1931c9db745967282ff8bfff51bc3faec0eade846b12203b75/langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-community\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/bb/72/4046a132a180b569265bc8aa7ecd6f958f6c11085bdf68c7e1bbe52f1907/langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting faiss-cpu\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/cb/cf/9caa08ca4e21ab935f82be0713e5d60566140414c3fff7932d9427c8fd72/faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/site-packages (3.1.5)\n",
      "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a9/bf/3464d759bf8687a3bbdfeb9af2f2aeb0a265c6d5ef5fd9274c2a70449f77/langchain_core-0.3.51-py3-none-any.whl (423 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/8b/a3/3696ff2444658053c01b6b7443e761f28bb71217d82bb89137a978c5f66f/langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/13/14/f2e972ac0cf9b4ff4d405f7843b0f14a1ef686544a54f91ac4d5ac723140/langsmith-0.3.26-py3-none-any.whl (357 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/site-packages (from langchain) (2.10.6)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/12/cf/b891a8c1d0c27ce9163361664c2128c7a57de3f35000ea5202eb3a2917b7/sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/site-packages (from langchain-community) (3.11.14)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain-community)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/e5/30/643397144bfbfec6f6ef821f36f33e57d35946c44a2352d3c9f0ae847619/tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/c3/be/d0d44e092656fe7a06b55e6103cbce807cdbdee17884a5367c68c9860853/dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/0b/53/a64f03044927dc47aafe029c42a5b7aabc38dfb813475e0e1bf71c4a59d0/pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/e1/9b/a181f281f65d776426002f330c31849b86b31fc9d848db62e16f03ff739f/httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/34/75/51952c7b2d3873b44a0028b1bd26a25078c18f92f256608e8d1dc61b39fd/marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.51->langchain)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: typing-inspect, tenacity, SQLAlchemy, marshmallow, jsonpatch, httpx-sse, faiss-cpu, dataclasses-json, pydantic-settings, langsmith, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
      "Successfully installed SQLAlchemy-2.0.40 dataclasses-json-0.6.7 faiss-cpu-1.10.0 httpx-sse-0.4.0 jsonpatch-1.33 langchain-0.3.23 langchain-community-0.3.21 langchain-core-0.3.51 langchain-text-splitters-0.3.8 langsmith-0.3.26 marshmallow-3.26.1 pydantic-settings-2.8.1 tenacity-9.1.2 typing-inspect-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-community faiss-cpu pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20af72b7-c945-48c7-8b0a-a05bbdf2c919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:__main__:初始化嵌入模型: all-MiniLM-L6-v2\n",
      "INFO:__main__:正在创建向量存储...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424cdc9aaeb544f3ba0ba107e0353cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:向量存储已保存到缓存文件: vector_store_cache.faiss\n",
      "INFO:__main__:正在处理查询: 数据中心是什么？\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0042ea9e56746f0b23df44583e97784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m基于以下上下文信息，请以专业的方式回答问题。如果无法从上下文中获得答案，请明确说明。\n",
      "\n",
      "    上下文：\n",
      "    问题：什么是核心网？\n",
      "答案：我们可以把核心网络想象成移动通信系统的“大脑”或“交通指挥中心”。它负责管理手机用户的通话、短信、上网数据，并确保这些信息正确、安全地传递到目的地（比如另一个手机、互联网服务器或银行系统）。它是连接用户设备与外部世界（如互联网或其他运营商网络）的关键枢纽，同时也是实现各种通信服务的核心所在。\n",
      "\n",
      "问题：数据中心规模区分\n",
      "答案：大规模数据中心规模巨大，拥有10000个以上标准机架；中型规模数据中心规模适中，拥有1000至3000个标准机架；边缘计算数据中心规模小，通常为小型或微型\n",
      "\n",
      "问题：核心网为什么重要？\n",
      "答案：核心网之所以重要，是因为它不仅决定了用户体验的质量，还影响着整个网络的安全性和效率。例如，在紧急情况下，如果核心网不能快速响应，则可能延误救援行动；同样地，如果没有良好的安全措施来保护核心网免受攻击，则可能导致敏感信息泄露。\n",
      "\n",
      "    问题：数据中心是什么？\n",
      "\n",
      "    请用中文提供结构清晰的回答：\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api-inference.modelscope.cn/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "=== 最终回答 ===\n",
      "根据提供的上下文信息，**无法直接获取“数据中心是什么”的明确定义**。上下文仅提供了关于数据中心规模的分类（大规模、中型、边缘计算数据中心）以及核心网的功能和重要性，但未对“数据中心”的概念进行基础性解释。\n",
      "\n",
      "若您需要进一步定义，可参考通用知识：  \n",
      "**数据中心**是用于存储、处理和分发大量数据的物理或虚拟设施，通常包含服务器、存储设备、网络设备、供电系统及冷却系统等，旨在为用户提供数据计算、存储、传输和应用服务。它是现代数字化基础设施的核心，支撑着云计算、大数据、人工智能等技术的运行，并与核心网等通信系统协同工作，确保数据高效安全地传递至用户或外部网络。  \n",
      "\n",
      "建议补充相关上下文以获得更精准的回答。\n",
      "\n",
      "=== 参考文档 ===\n",
      "- 问题：什么是核心网？\n",
      "答案：我们可以把核心网络想象成移动通信系统的“大脑”或“交通指挥中心”。它负责管理手机用户的通话、短信、上网数据，并确保这些信息正确、安全...\n",
      "- 问题：数据中心规模区分\n",
      "答案：大规模数据中心规模巨大，拥有10000个以上标准机架；中型规模数据中心规模适中，拥有1000至3000个标准机架；边缘计算数据中心...\n",
      "- 问题：核心网为什么重要？\n",
      "答案：核心网之所以重要，是因为它不仅决定了用户体验的质量，还影响着整个网络的安全性和效率。例如，在紧急情况下，如果核心网不能快速响应，...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from dataclasses import dataclass, field\n",
    "import logging\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ---- 配置类 ----\n",
    "@dataclass\n",
    "class RAGConfig:\n",
    "    \"\"\"RAG 管道配置参数\"\"\"\n",
    "    # 嵌入模型配置\n",
    "    embedding_model: str = \"text2vec-base-chinese\"\n",
    "    # embedding_model: str =\"all-MiniLM-L6-v2\"\n",
    "    # 检索配置\n",
    "    search_top_k: int = 3\n",
    "    search_type: str = \"similarity\"\n",
    "    \n",
    "    # 模型服务配置\n",
    "    llm_model_name: str = \"Qwen/QwQ-32B\"\n",
    "    llm_api_base: str = \"https://api-inference.modelscope.cn/v1/\"\n",
    "    llm_streaming: bool = True\n",
    "    llm_temperature: float = 0.3\n",
    "    \n",
    "    # 提示模板\n",
    "    prompt_template: str = \"\"\"基于以下上下文信息，请以专业的方式回答问题。如果无法从上下文中获得答案，请明确说明。\n",
    "    \n",
    "    上下文：\n",
    "    {context}\n",
    "    \n",
    "    问题：{question}\n",
    "    \n",
    "    请用中文提供结构清晰的回答：\"\"\"\n",
    "    \n",
    "    # 文档处理配置\n",
    "    chunk_size: int = 500\n",
    "    chunk_overlap: int = 50\n",
    "    \n",
    "    # 缓存配置\n",
    "    cache_file_path: Path = field(default_factory=lambda: Path(\"vector_store_cache.faiss\"))\n",
    "    \n",
    "    # 安全配置\n",
    "    allow_dangerous_deserialization: bool = True\n",
    "    \n",
    "    # 调试配置\n",
    "    verbose: bool = True\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        \"\"\"参数验证\"\"\"\n",
    "        if self.search_top_k <= 0:\n",
    "            raise ValueError(\"search_top_k 必须为正整数\")\n",
    "        if self.chunk_overlap >= self.chunk_size:\n",
    "            raise ValueError(\"chunk_overlap 不能大于 chunk_size\")\n",
    "        if not (0 <= self.llm_temperature <= 2):\n",
    "            raise ValueError(\"temperature 必须在 0-2 之间\")\n",
    "\n",
    "    @classmethod\n",
    "    def from_yaml(cls, file_path: Path) -> \"RAGConfig\":\n",
    "        \"\"\"从 YAML 文件加载配置\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                config_data = yaml.safe_load(f)\n",
    "            \n",
    "            # 确保 cache_file_path 是 Path 对象\n",
    "            if isinstance(config_data.get('cache_file_path'), str):\n",
    "                config_data['cache_file_path'] = Path(config_data['cache_file_path'])\n",
    "            \n",
    "            return cls(**config_data)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"YAML 配置加载失败: {e}\")\n",
    "            raise\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, file_path: Path) -> \"RAGConfig\":\n",
    "        \"\"\"从 JSON 文件加载配置\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                config_data = json.load(f)\n",
    "            \n",
    "            # 确保 cache_file_path 是 Path 对象\n",
    "            if isinstance(config_data.get('cache_file_path'), str):\n",
    "                config_data['cache_file_path'] = Path(config_data['cache_file_path'])\n",
    "            \n",
    "            return cls(**config_data)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"JSON 配置加载失败: {e}\")\n",
    "            raise\n",
    "\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"转换为字典（用于持久化）\"\"\"\n",
    "        return self.__dict__\n",
    "\n",
    "# ---- 嵌入模型封装 ----\n",
    "class SentenceTransformerEmbeddings(Embeddings):\n",
    "    \"\"\"自定义句子嵌入模型封装\"\"\"\n",
    "    def __init__(self, config: RAGConfig) -> None:\n",
    "        self.model = SentenceTransformer(config.embedding_model)\n",
    "        logger.info(f\"初始化嵌入模型: {config.embedding_model}\")\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self.model.encode(texts).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.model.encode(text).tolist()\n",
    "\n",
    "# ---- 模块初始化函数 ----\n",
    "def initialize_embeddings(config: RAGConfig) -> SentenceTransformerEmbeddings:\n",
    "    \"\"\"初始化嵌入模型\"\"\"\n",
    "    return SentenceTransformerEmbeddings(config)\n",
    "\n",
    "def initialize_vector_store(\n",
    "    texts: List[str], \n",
    "    embeddings: Embeddings,\n",
    "    config: RAGConfig\n",
    ") -> FAISS:\n",
    "    \"\"\"初始化向量数据库\"\"\"\n",
    "    try:\n",
    "        # 检查缓存文件是否存在\n",
    "        if config.cache_file_path.exists():\n",
    "            logger.warning(\"注意：正在启用不安全的反序列化选项。确保你信任缓存文件的来源！\")\n",
    "            vector_store = FAISS.load_local(\n",
    "                str(config.cache_file_path.parent), \n",
    "                embeddings, \n",
    "                index_name=config.cache_file_path.stem, \n",
    "                allow_dangerous_deserialization=config.allow_dangerous_deserialization\n",
    "            )\n",
    "        else:\n",
    "            logger.info(\"正在创建向量存储...\")\n",
    "            vector_store = FAISS.from_texts(\n",
    "                texts=texts,\n",
    "                embedding=embeddings,\n",
    "                metadatas=[{\"source\": f\"doc_{i}\"} for i in range(len(texts))]\n",
    "            )\n",
    "            # 保存到缓存文件\n",
    "            vector_store.save_local(str(config.cache_file_path.parent), index_name=config.cache_file_path.stem)\n",
    "            logger.info(f\"向量存储已保存到缓存文件: {config.cache_file_path}\")\n",
    "        return vector_store\n",
    "    except Exception as e:\n",
    "        logger.error(f\"向量存储初始化失败: {e}\")\n",
    "        raise\n",
    "\n",
    "def initialize_llm(config: RAGConfig) -> ChatOpenAI:\n",
    "    \"\"\"初始化大语言模型\"\"\"\n",
    "    # api_key = os.getenv(\"OPENAI_API_KEY\", \"XXXXXXX\")\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    \n",
    "    # api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"未找到 OPENAI_API_KEY 环境变量\")\n",
    "\n",
    "    return ChatOpenAI(\n",
    "        openai_api_base=config.llm_api_base,\n",
    "        openai_api_key=api_key,\n",
    "        model_name=config.llm_model_name,\n",
    "        streaming=config.llm_streaming,\n",
    "        temperature=config.llm_temperature\n",
    "    )\n",
    "\n",
    "def build_qa_chain(\n",
    "    vector_store: FAISS,\n",
    "    llm: ChatOpenAI,\n",
    "    config: RAGConfig\n",
    ") -> RetrievalQA:\n",
    "    \"\"\"构建检索问答链\"\"\"\n",
    "    # 配置检索器\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=config.search_type,\n",
    "        search_kwargs={\"k\": config.search_top_k}\n",
    "    )\n",
    "    \n",
    "    # 构建提示模板\n",
    "    prompt = PromptTemplate(\n",
    "        template=config.prompt_template,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    # 配置问答链\n",
    "    return RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\n",
    "            \"prompt\": prompt,\n",
    "            \"verbose\": config.verbose\n",
    "        }\n",
    "    )\n",
    "import pandas as pd\n",
    "\n",
    "def read_excel_qa_pairs(file_paths: List[str]) -> List[str]:\n",
    "    corpus = []\n",
    "    seen = set()\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_excel(file_path, sheet_name=\"Sheet1\")\n",
    "        for _, row in df.iterrows():\n",
    "            text = f\"问题：{row['问题']}\\n答案：{row['答案']}\"\n",
    "            if text not in seen:\n",
    "                corpus.append(text)\n",
    "                seen.add(text)\n",
    "    # print(len(corpus))\n",
    "    return corpus\n",
    "    \n",
    "def main(config: RAGConfig) -> None:\n",
    "    \"\"\"RAG 主流程\"\"\"\n",
    "    # 读取Excel文件\n",
    "    excel_files = [\"全网运行指标问题.xlsx\", \"数字人问答.xlsx\"]\n",
    "    corpus = read_excel_qa_pairs(excel_files)\n",
    "    \n",
    "    try:\n",
    "        # 初始化各组件\n",
    "        embeddings = initialize_embeddings(config)\n",
    "        vector_store = initialize_vector_store(corpus, embeddings, config)\n",
    "        llm = initialize_llm(config)\n",
    "        qa_chain = build_qa_chain(vector_store, llm, config)\n",
    "        \n",
    "        # 执行查询\n",
    "        query = \"数据中心是什么？\"\n",
    "        logger.info(f\"正在处理查询: {query}\")\n",
    "        \n",
    "        # 获取完整响应\n",
    "        response = qa_chain({\"query\": query})\n",
    "        \n",
    "        # 输出结果\n",
    "        print(\"\\n=== 最终回答 ===\")\n",
    "        print(response[\"result\"])\n",
    "        \n",
    "        # 显示参考来源\n",
    "        if config.verbose:\n",
    "            print(\"\\n=== 参考文档 ===\")\n",
    "            for doc in response[\"source_documents\"]:\n",
    "                print(f\"- {doc.page_content[:80]}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"流程执行失败: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 使用方式 1: 默认配置\n",
    "    # main(RAGConfig())\n",
    "    \n",
    "    # # 使用方式 2: 从 YAML 加载配置\n",
    "    config = RAGConfig.from_yaml(Path(\"config.yml\"))\n",
    "    main(config)\n",
    "    \n",
    "    # # 使用方式 3: 从 JSON 加载配置\n",
    "    # config = RAGConfig.from_json(Path(\"config.json\"))\n",
    "    # main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9432d8-b700-4518-8726-e54d58ca0fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
